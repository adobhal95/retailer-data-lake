{"cells": [{"cell_type": "code", "execution_count": 7, "id": "53c1c559-c7ae-40db-940a-c3e67fcc526a", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nimport requests\nimport json\nimport pandas as pd\nimport datetime\nfrom google.cloud import storage"}, {"cell_type": "code", "execution_count": 8, "id": "3ed756e8-8936-406c-824c-75c7a649fcfe", "metadata": {}, "outputs": [], "source": "# initialize spark session\nspark = SparkSession.builder.appName(\"customer_reviews_api_ingestion\")\\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 9, "id": "b7131ebb-e5ac-4791-b4aa-4f769cf2720a", "metadata": {}, "outputs": [], "source": "def get_api_response(api_url:str):\n    \"\"\"\n    Fetch the latest api response from the api\n    Returns:\n        Pandas DataFrame\n    \"\"\"\n    try:\n        response = requests.get(api_url)\n        if response.status_code == 200:\n            data = response.json()\n            print(f\"data fetched from api, total records fetched: {len(data)}\")\n            # convert the json data to pandas dataframe\n            df = pd.DataFrame(data)\n            return df\n    except Exception as e:\n        print(f\"error occured while fetching data, status_code:{response.status_code}\")\n        exit()"}, {"cell_type": "code", "execution_count": 10, "id": "144d7cc2-775b-4ef6-b68e-9834afab181e", "metadata": {}, "outputs": [], "source": "def store_data_in_gcs(local_file_name:str,bucket_name:str,target_path:str):\n    \"\"\"\n    stores the latest reviews in gcs bucket in parquet format\n    Returns:\n        None\n    \"\"\"\n    \n    storage_client = storage.Client()\n    bucket = storage_client.bucket(bucket_name)\n    blob = bucket.blob(target_path)\n    # upload the parquet file to gcs\n    blob.upload_from_filename(local_file_name)\n    print(f\"data successfully written to gs://{bucket_name}/{target_path}\")"}, {"cell_type": "code", "execution_count": 11, "id": "d66d3579-e7eb-4030-93b1-3e8f2990df1f", "metadata": {}, "outputs": [], "source": "def api_start_process():\n    # review api url\n    url = \"https://6879045063f24f1fdca07d19.mockapi.io/api/v1/retailer/reviews\"\n    df = get_api_response(url)\n    # current data for file name\n    today = datetime.datetime.now().strftime(\"%Y%m%d\") # format: YYYYMMDD \n    # define File Paths with Date\n    local_parquet_file = f\"/tmp/customer_reviews_{today}.parquet\"\n    GCS_BUCKET = \"retailer-datalake\"\n    GCS_PATH = f\"landing/customer_reviews/customer_reviews_{today}.parquet\"\n    \n    # save parquet file to local path\n    df.to_parquet(local_parquet_file,index=False)\n    store_data_in_gcs(local_parquet_file,GCS_BUCKET,GCS_PATH)"}, {"cell_type": "code", "execution_count": 12, "id": "8ac0041d-a60f-48f8-afda-fe5741286b76", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "data fetched from api, total records fetched: 85\ndata successfully written to gs://retailer-datalake/landing/customer_reviews/customer_reviews_20250719.parquet\n"}], "source": "api_start_process()"}, {"cell_type": "code", "execution_count": null, "id": "725b3ebd-ea6e-4d42-8459-76f6f81d9d01", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}